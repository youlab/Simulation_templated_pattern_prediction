{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1165504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and config files\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from diffusers import AutoencoderKL\n",
    "import numpy as np\n",
    "from models.vae import encode_img, decode_img\n",
    "\n",
    "from utils.config import SIMULATED_FOLDER,EXPERIMENTAL_FOLDER, FILES_FIG1A\n",
    "from utils.preprocess import preprocess_simulation_output_data, preprocess_experimental_backgroundwhite_rawfiles\n",
    "from utils.preprocess import scale_latents\n",
    "from utils.display import display_images_with_ssim_3rows\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18b7dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the comparisions for 4 files, first two from files fig1a, 2 simulations and 2 exps\n",
    "\n",
    "selected_files= FILES_FIG1A[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ddd456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression ratio for SDVAE: 12.0\n",
      "BPP for SDVAE images: 2.0\n"
     ]
    }
   ],
   "source": [
    "# BPP for SDVAE images\n",
    "# 32x 32 x4 images, 32 bit precision\n",
    "# bpp = (32 * 32 * 4 channels * 32bits) / (256 x 256 x 3 x 8bits)  # bits per pixel calculation\n",
    "\n",
    "compression_bpp= 256 * 256 * 3 * 8 / (32 * 32 * 4 * 32)  # bits per pixel calculation\n",
    "print(f\"Compression ratio for SDVAE: {compression_bpp}\")\n",
    "\n",
    "bpp_sdvae= 24/compression_bpp  # 24= 8 bits per channel for 3 channels rgb\n",
    "print(f\"BPP for SDVAE images: {bpp_sdvae}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "308350ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target BPP for SDVAE: 2.0000\n",
      "BPP results with 2.5x downsampling is 2.18212890625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# compare the bpp results with jpeg compression \n",
    "\n",
    "\n",
    "def jpeg_bytes_and_bpp(img_path, quality):\n",
    "    im = Image.open(img_path).convert(\"RGB\")\n",
    "    H, W = im.height, im.width\n",
    "    buf = io.BytesIO()\n",
    "    im.save(buf, \"JPEG\", quality=quality, subsampling=0, optimize=True,\n",
    "            progressive=False)  # don't pass exif/icc\n",
    "    data = buf.getvalue()\n",
    "    bpp = (len(data)*8)/(H*W)\n",
    "    return data, bpp\n",
    "\n",
    "# JPEG compression \n",
    "\n",
    "# image_file='/hpc/group/youlab/ks723/storage/Random_images/SSIM_comparisions/cameraman.png'\n",
    "image_file=os.path.join(SIMULATED_FOLDER,selected_files[0]) # demo test with a simulated file\n",
    "qualities = [80, 85, 86, 88, 90, 95]\n",
    "bpp_dict = {}  # Dictionary to store quality: bpp pairs\n",
    "\n",
    "for q in qualities:\n",
    "    _, bpp = jpeg_bytes_and_bpp(image_file, quality=q)\n",
    "    bpp_dict[q] = bpp  # Store quality as key, bpp as value\n",
    "   \n",
    "\n",
    "# Find the first quality level where BPP >= bpp_sdvae\n",
    "quality_desired=None\n",
    "bpp_desired = None\n",
    "for q in qualities:\n",
    "    if bpp_dict[q] >= bpp_sdvae:\n",
    "        quality_desired = q\n",
    "        bpp_desired = bpp_dict[q]\n",
    "        break\n",
    "\n",
    "print(f\"\\nTarget BPP for SDVAE: {bpp_sdvae:.4f}\")\n",
    "if quality_desired:\n",
    "    print(f\"Closest JPEG quality: {quality_desired}, BPP: {bpp_desired:.4f}\")\n",
    "\n",
    "\n",
    "# Downsampling and upsampling by resize function\n",
    "# load folder\n",
    "input_folder = '/hpc/group/youlab/ks723/storage/Random_images/SSIM_comparisions'  # Path with original images\n",
    "filename='cameraman.png'\n",
    "\n",
    "value_downsampling= 2.5 # found by rough checking ~ 2.0\n",
    "\n",
    "def bpp_of_downscaled(path_in, H_orig, W_orig, scale):\n",
    "    img = cv2.imread(path_in, cv2.IMREAD_COLOR)\n",
    "    h, w = int(H_orig/scale), int(W_orig/scale)\n",
    "    small = cv2.resize(img, (w, h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    base, ext = os.path.splitext(path_in)\n",
    "    out_path_small = f\"{base}_downsampled_{scale}{ext}\"\n",
    "    cv2.imwrite(out_path_small,small)  # PNG default compression\n",
    "\n",
    "    # write the upscaled version from the downsampled version\n",
    "    upsampled= cv2.resize(small, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    out_path_resized=f\"{base}_upsampled_{scale}{ext}\"\n",
    "    cv2.imwrite(out_path_resized, upsampled)\n",
    "\n",
    "    bytes_on_disk = os.path.getsize(out_path_small)\n",
    "\n",
    "    return (bytes_on_disk * 8) / (H_orig * W_orig)\n",
    "\n",
    "bpp_downsampled=bpp_of_downscaled(os.path.join(input_folder,filename),256,256,value_downsampling)\n",
    "print(f\"BPP results with {value_downsampling}x downsampling is {bpp_downsampled}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c52f8f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{80: 0.9703708726015323,\n",
       " 85: 1.0560715980744457,\n",
       " 86: 1.07959861685538,\n",
       " 88: 1.1229235880398671,\n",
       " 90: 1.172554071462472,\n",
       " 95: 1.3621940470540375}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4602b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sim_data = preprocess_simulation_output_data(SIMULATED_FOLDER, 0, len(selected_files), img_filenames=selected_files)\n",
    "sim_images = [data[0] for data in sim_data]  # Extract images (grayscale)\n",
    "sim_images = np.array(sim_images)\n",
    "\n",
    "# Experimental - use preprocessing function\n",
    "exp_data = preprocess_experimental_backgroundwhite_rawfiles(EXPERIMENTAL_FOLDER, 0, len(selected_files), img_filenames=selected_files)\n",
    "exp_images = exp_data  # This is already a list of images (RGB)\n",
    "exp_images= np.array(exp_images)\n",
    "\n",
    "# Use the VAE to compute the reconstructed version\n",
    "# Convert grayscale to RGB for simulation and normalize\n",
    "sim_rgb = np.stack([sim_images, sim_images, sim_images], axis=-1)  # Make RGB\n",
    "sim_rgb = np.transpose(sim_rgb, (0, 3, 1, 2)) / 255.0  # Normalize and reorder\n",
    "\n",
    "# Convert to tensor and encode\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "X = torch.Tensor(sim_rgb)\n",
    "\n",
    "# Simple encoding (one batch at a time)\n",
    "encoded_latents = []\n",
    "for i in range(X.shape[0]):\n",
    "    latent = encode_img(X[i:i+1].to(device))\n",
    "    encoded_latents.append(latent.cpu())\n",
    "\n",
    "# Combine results\n",
    "latents_sim = torch.cat(encoded_latents, dim=0)\n",
    "latents_scaled_sim = scale_latents(latents_sim)\n",
    "reconstructed = decode_img(latents_sim)\n",
    "\n",
    "\n",
    "exp_images = np.transpose(exp_images, (0, 3, 1, 2)) / 255.0  # Normalize and reorder\n",
    "X = torch.Tensor(exp_images)\n",
    "\n",
    "# Simple encoding (one batch at a time)  \n",
    "encoded_latents = []\n",
    "for i in range(X.shape[0]): \n",
    "    latent = encode_img(X[i:i+1].to(device))\n",
    "    encoded_latents.append(latent.cpu())\n",
    "\n",
    "# Combine results\n",
    "latents_exp = torch.cat(encoded_latents, dim=0)\n",
    "latents_scaled_exp = scale_latents(latents_exp)\n",
    "reconstructed_exp = decode_img(latents_exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac49a989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_PA_patternprediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

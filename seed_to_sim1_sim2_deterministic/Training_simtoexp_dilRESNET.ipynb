{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTraining file: Train a NN to map from simulation(intermediate) to experiments\\nMapping Sim -> Exp (Supp Fig x)\\n\\nGeneral workflow: \\n1) Load train data- input and output are latent images from pre-trained Stable Diffusion VAE\\n2) Define NN model \\n3) Run the training and save the model weights\\n4) Plot the training and validation performance \\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training file: Train a NN to map from simulation(intermediate) to experiments\n",
    "Mapping Sim -> Exp (Supp Fig x)\n",
    "\n",
    "General workflow: \n",
    "1) Load train data- input and output are latent images from pre-trained Stable Diffusion VAE\n",
    "2) Define NN model \n",
    "3) Run the training and save the model weights\n",
    "4) Plot the training and validation performance \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pickle\n",
    "import json\n",
    "from pytorch_msssim import ssim\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading desired output datset- simulated patterns (latent embeddings of this)\n",
    "\"\"\"\n",
    "\n",
    "foldername='/hpc/group/youlab/ks723/miniconda3/Lingchong/Latents'\n",
    "latentname_input='latent_dim_SimcorrtoExp_images_40900_4channels_4x32x32_07092024.pickle'\n",
    "latentname_output='latent_dim_Exp_images_40900_BnW_4channels_4x32x32_07092024.pickle'\n",
    "\n",
    "filename_input=os.path.join(foldername,latentname_input)\n",
    "filename_output=os.path.join(foldername,latentname_output)\n",
    "\n",
    "pickle_in=open(filename_input,\"rb\")\n",
    "yprime_in=pickle.load(pickle_in)\n",
    "yprime_in=yprime_in[:30000,:,:,:]\n",
    "yprime_in=torch.Tensor(yprime_in)\n",
    "yprime_in=yprime_in.float()\n",
    "\n",
    "pickle_out=open(filename_output,\"rb\")\n",
    "yprime_out=pickle.load(pickle_out)\n",
    "yprime_out=yprime_out[:30000,:,:,:]\n",
    "yprime_out=torch.Tensor(yprime_out)\n",
    "yprime_out=yprime_out.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining dataset \n",
    "\"\"\"\n",
    "\n",
    "# Define train and test datasets\n",
    "dataset = torch.utils.data.TensorDataset(yprime_in, yprime_out)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size=64\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(val_dataset,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining NN model (Here: dilResNet)\n",
    "\"\"\"\n",
    "\n",
    "# Dilated Basic Block similar to PDEArena\n",
    "class PDEArenaDilatedBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, dilation_rates, activation=nn.ReLU, norm=True):\n",
    "        super(PDEArenaDilatedBlock, self).__init__()\n",
    "\n",
    "        # Create dilated convolution layers with specified dilation rates\n",
    "        self.dilated_layers = nn.ModuleList([\n",
    "            nn.Conv2d(\n",
    "                in_planes if i == 0 else out_planes, \n",
    "                out_planes, \n",
    "                kernel_size=3, \n",
    "                padding=rate, \n",
    "                dilation=rate, \n",
    "                bias=False\n",
    "            )\n",
    "            for i, rate in enumerate(dilation_rates)\n",
    "        ])\n",
    "        \n",
    "        # Normalization and Activation layers\n",
    "        self.norm_layers = nn.ModuleList([nn.BatchNorm2d(out_planes) if norm else nn.Identity() for _ in dilation_rates])\n",
    "        self.activation = activation(inplace=True)\n",
    "\n",
    "        # Shortcut (1x1 convolution if input and output planes differ)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_planes) if norm else nn.Identity()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for layer, norm in zip(self.dilated_layers, self.norm_layers):\n",
    "            out = self.activation(norm(layer(out)))\n",
    "        return out + self.shortcut(x)  # Residual connection\n",
    "\n",
    "# Dilated ResNet with Adjustable Layers and Blocks\n",
    "class PDEArenaDilatedResNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels=64, num_blocks=15, dilation_rates=[1, 2, 4, 8], activation=nn.ReLU, norm=True):\n",
    "        super(PDEArenaDilatedResNet, self).__init__()\n",
    "        \n",
    "        self.in_conv = nn.Conv2d(in_channels, hidden_channels, kernel_size=3, padding=1)  # Input layer\n",
    "        \n",
    "        # Stack of dilated blocks\n",
    "        self.layers = nn.Sequential(\n",
    "            *[PDEArenaDilatedBlock(hidden_channels, hidden_channels, dilation_rates, activation=activation, norm=norm) for _ in range(num_blocks)]\n",
    "        )\n",
    "        \n",
    "        self.out_conv = nn.Conv2d(hidden_channels, out_channels, kernel_size=3, padding=1)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_conv(x)\n",
    "        x = self.layers(x)\n",
    "        return self.out_conv(x)\n",
    "\n",
    "# Example usage\n",
    "model = PDEArenaDilatedResNet(\n",
    "    in_channels=4,               # Input channels (e.g., RGB image)\n",
    "    out_channels=4,              # Output channels (e.g., RGB image or latent channels)\n",
    "    hidden_channels=64,          # Number of hidden channels\n",
    "    num_blocks=15,               # Number of dilated blocks (similar to number of ResNet blocks)\n",
    "    dilation_rates=[1, 2, 4, 8], # Dilation rates for multi-scale feature capture\n",
    "    activation=nn.ReLU,          # Activation function\n",
    "    norm=True                    # Use BatchNorm after each convolution\n",
    ")\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Total Parameters in Neural Network: 2224196\n",
      "Epoch 1: Significant improvement observed. Best Validation Loss updated to 0.548711.\n",
      "Epoch [2/500] | Train Total Loss: 0.513131 | Test Total Loss: 0.492013 | LR: 0.0001000\n",
      "Epoch 2: Significant improvement observed. Best Validation Loss updated to 0.492013.\n",
      "Epoch 3: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [4/500] | Train Total Loss: 0.478262 | Test Total Loss: 0.472438 | LR: 0.0002000\n",
      "Epoch 4: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 5: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [6/500] | Train Total Loss: 0.464905 | Test Total Loss: 0.456721 | LR: 0.0003000\n",
      "Epoch 6: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 7: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [8/500] | Train Total Loss: 0.454549 | Test Total Loss: 0.464782 | LR: 0.0004000\n",
      "Epoch 8: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 9: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [10/500] | Train Total Loss: 0.442691 | Test Total Loss: 0.449311 | LR: 0.0005000\n",
      "Epoch 10: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 11: Significant improvement observed. Best Validation Loss updated to 0.432093.\n",
      "Epoch [12/500] | Train Total Loss: 0.424548 | Test Total Loss: 0.433246 | LR: 0.0004901\n",
      "Epoch 12: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 13: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [14/500] | Train Total Loss: 0.411009 | Test Total Loss: 0.407173 | LR: 0.0004803\n",
      "Epoch 14: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 15: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [16/500] | Train Total Loss: 0.396943 | Test Total Loss: 0.402229 | LR: 0.0004707\n",
      "Epoch 16: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 17: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [18/500] | Train Total Loss: 0.387643 | Test Total Loss: 0.394744 | LR: 0.0004614\n",
      "Epoch 18: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 19: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [20/500] | Train Total Loss: 0.377831 | Test Total Loss: 0.388923 | LR: 0.0004522\n",
      "Epoch 20: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 21: Significant improvement observed. Best Validation Loss updated to 0.379462.\n",
      "Epoch 22: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 23: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 24: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 25: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 26: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 27: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 28: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 29: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 30: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 31: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 32: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 33: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 34: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 35: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 36: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 37: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 38: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 39: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [40/500] | Train Total Loss: 0.308784 | Test Total Loss: 0.337815 | LR: 0.0003699\n",
      "Epoch 40: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 41: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 42: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 43: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 44: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 45: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 46: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 47: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 48: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 49: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 50: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 51: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 52: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 53: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 54: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 55: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 56: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 57: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 58: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 59: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 60: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 61: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 62: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 63: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 64: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 65: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 66: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 67: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 68: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 69: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 70: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 71: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 72: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 73: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 74: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 75: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 76: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 77: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 78: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 79: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [80/500] | Train Total Loss: 0.275970 | Test Total Loss: 0.334131 | LR: 0.0002474\n",
      "Epoch 80: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 81: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 82: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 83: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 84: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 85: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 86: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 87: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 88: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 89: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 90: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 91: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 92: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 93: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 94: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 95: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 96: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 97: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 98: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 99: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 100: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 101: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 102: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 103: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 104: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 105: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 106: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 107: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 108: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 109: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 110: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 111: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 112: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 113: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 114: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 115: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 116: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 117: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 118: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 119: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [120/500] | Train Total Loss: 0.261624 | Test Total Loss: 0.336312 | LR: 0.0001655\n",
      "Epoch 120: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 121: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 122: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 123: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 124: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 125: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 126: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 127: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 128: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 129: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 130: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 131: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 132: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 133: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 134: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 135: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 136: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 137: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 138: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 139: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 140: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 141: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 142: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 143: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 144: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 145: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 146: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 147: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 148: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 149: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 150: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 151: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 152: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 153: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 154: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 155: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 156: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 157: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 158: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 159: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [160/500] | Train Total Loss: 0.253093 | Test Total Loss: 0.344109 | LR: 0.0001107\n",
      "Epoch 160: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 161: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 162: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 163: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 164: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 165: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 166: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 167: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 168: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 169: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 170: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 171: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 172: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 173: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 174: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 175: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 176: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 177: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 178: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 179: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 180: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 181: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 182: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 183: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 184: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 185: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 186: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 187: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 188: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 189: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 190: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 191: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 192: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 193: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 194: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 195: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 196: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 197: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 198: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 199: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [200/500] | Train Total Loss: 0.246955 | Test Total Loss: 0.352945 | LR: 0.0000741\n",
      "Epoch 200: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 201: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 202: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 203: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 204: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 205: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 206: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 207: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 208: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 209: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 210: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 211: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 212: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 213: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 214: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 215: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 216: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 217: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 218: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 219: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 220: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 221: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 222: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 223: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 224: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 225: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 226: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 227: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 228: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 229: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 230: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 231: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 232: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 233: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 234: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 235: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 236: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 237: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 238: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 239: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [240/500] | Train Total Loss: 0.242825 | Test Total Loss: 0.359101 | LR: 0.0000496\n",
      "Epoch 240: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 241: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 242: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 243: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 244: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 245: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 246: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 247: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 248: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 249: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 250: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 251: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 252: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 253: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 254: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 255: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 256: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 257: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 258: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 259: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 260: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 261: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 262: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 263: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 264: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 265: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 266: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 267: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 268: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 269: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 270: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 271: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 272: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 273: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 274: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 275: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 276: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 277: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 278: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 279: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [280/500] | Train Total Loss: 0.239578 | Test Total Loss: 0.364700 | LR: 0.0000331\n",
      "Epoch 280: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 281: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 282: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 283: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 284: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 285: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 286: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 287: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 288: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 289: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 290: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 291: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 292: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 293: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 294: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 295: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 296: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 297: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 298: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 299: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 300: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 301: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 302: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 303: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 304: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 305: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 306: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 307: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 308: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 309: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 310: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 311: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 312: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 313: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 314: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 315: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 316: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 317: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 318: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 319: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [320/500] | Train Total Loss: 0.237067 | Test Total Loss: 0.370774 | LR: 0.0000222\n",
      "Epoch 320: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 321: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 322: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 323: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 324: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 325: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 326: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 327: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 328: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 329: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 330: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 331: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 332: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 333: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 334: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 335: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 336: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 337: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 338: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 339: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 340: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 341: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 342: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 343: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 344: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 345: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 346: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 347: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 348: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 349: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 350: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 351: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 352: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 353: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 354: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 355: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 356: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 357: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 358: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 359: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [360/500] | Train Total Loss: 0.235707 | Test Total Loss: 0.374426 | LR: 0.0000148\n",
      "Epoch 360: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 361: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 362: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 363: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 364: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 365: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 366: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 367: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 368: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 369: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 370: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 371: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 372: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 373: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 374: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 375: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 376: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 377: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 378: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 379: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 380: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 381: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 382: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 383: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 384: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 385: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 386: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 387: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 388: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 389: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 390: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 391: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 392: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 393: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 394: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 395: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 396: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 397: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 398: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 399: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [400/500] | Train Total Loss: 0.234560 | Test Total Loss: 0.377896 | LR: 0.0000099\n",
      "Epoch 400: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 401: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 402: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 403: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 404: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 405: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 406: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 407: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 408: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 409: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 410: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 411: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 412: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 413: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 414: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 415: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 416: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 417: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 418: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 419: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 420: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 421: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 422: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 423: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 424: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 425: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 426: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 427: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 428: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 429: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 430: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 431: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 432: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 433: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 434: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 435: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 436: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 437: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 438: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 439: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [440/500] | Train Total Loss: 0.233835 | Test Total Loss: 0.379468 | LR: 0.0000066\n",
      "Epoch 440: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 441: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 442: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 443: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 444: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 445: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 446: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 447: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 448: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 449: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 450: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 451: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 452: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 453: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 454: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 455: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 456: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 457: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 458: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 459: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 460: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 461: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 462: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 463: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 464: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 465: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 466: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 467: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 468: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 469: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 470: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 471: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 472: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 473: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 474: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 475: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 476: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 477: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 478: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 479: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [480/500] | Train Total Loss: 0.233341 | Test Total Loss: 0.381143 | LR: 0.0000050\n",
      "Epoch 480: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 481: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 482: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 483: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 484: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 485: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 486: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 487: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 488: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 489: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 490: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 491: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 492: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 493: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 494: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 495: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 496: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 497: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 498: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 499: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [500/500] | Train Total Loss: 0.233368 | Test Total Loss: 0.381337 | LR: 0.0000050\n",
      "Epoch 500: Validation loss increased but within tolerance (0.05). Continuing training.\n"
     ]
    }
   ],
   "source": [
    "currentSecond= datetime.now().second\n",
    "currentMinute = datetime.now().minute\n",
    "currentHour = datetime.now().hour\n",
    "\n",
    "currentDay = datetime.now().day\n",
    "currentMonth = datetime.now().month\n",
    "currentYear = datetime.now().year\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 500       \n",
    "warmup_epochs=10\n",
    "lr = 5e-4               #for fine tuning.\n",
    "min_lr = 5e-6\n",
    "gamma = 0.99\n",
    "\n",
    "train_losses=[]\n",
    "test_losses=[]\n",
    "\n",
    "# Training parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "print(f\"Total Parameters in Neural Network: {count_parameters(model)}\")\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Initialize lists to store individual and combined losses\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "\n",
    "# Training parameters and early stopping initialization\n",
    "best_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "patience = 30  # Note: Initially set to 30\n",
    "delta = 0.05 \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_params, batch_latents in train_loader:\n",
    "\n",
    "            \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move data to device\n",
    "        inputs = batch_params.to(device)\n",
    "        targets = batch_latents.squeeze(1).to(device)  # Adjust as per your data dimensions\n",
    "    \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss \n",
    "        loss = criterion(outputs,targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Warm-up schedule: Adjust learning rate during initial epochs\n",
    "        if epoch < warmup_epochs:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * (epoch + 1) / warmup_epochs\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate losses for averaging\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    \n",
    "    # Scheduler step after warmup\n",
    "    if epoch >= warmup_epochs:\n",
    "        scheduler.step()\n",
    "    # Ensure learning rate doesn't go below min_lr\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = max(param_group['lr'], min_lr)\n",
    "    \n",
    "    # Validation loop for testing set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_params, batch_latents in test_loader:\n",
    "            # Move data to device\n",
    "            inputs = batch_params.to(device)\n",
    "            targets = batch_latents.squeeze(1).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute combined loss and individual components\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Accumulate validation losses\n",
    "            val_loss += loss.item()\n",
    "          \n",
    "    \n",
    "    # Calculate average losses\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    \n",
    "    # Store losses in respective lists\n",
    "    train_losses.append(avg_train_loss)\n",
    "    test_losses.append(avg_val_loss)\n",
    "\n",
    "    \n",
    "    # Determine logging interval\n",
    "    interval = 2 if epoch < 20 else 40\n",
    "    \n",
    "    # Print loss information at specified intervals or at the last epoch\n",
    "    if (epoch + 1) % interval == 0 or epoch + 1 == num_epochs:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] | \"\n",
    "              f\"Train Total Loss: {avg_train_loss:.6f} | \"\n",
    "              f\"Test Total Loss: {avg_val_loss:.6f} | \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.7f}\")\n",
    "    \n",
    "    # Early stopping logic with tolerance\n",
    "   \n",
    "    if avg_val_loss < best_loss - delta:\n",
    "        # Significant improvement\n",
    "        best_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        print(f\"Epoch {epoch + 1}: Significant improvement observed. \"\n",
    "              f\"Best Validation Loss updated to {best_loss:.6f}.\")\n",
    "    elif avg_val_loss <= best_loss + delta:\n",
    "        # Within tolerance\n",
    "        epochs_without_improvement = 0\n",
    "        print(f\"Epoch {epoch + 1}: Validation loss increased but within tolerance ({delta}). \"\n",
    "              f\"Continuing training.\")\n",
    "    else:\n",
    "        # Exceeded tolerance\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Epoch {epoch + 1}: Validation loss increased beyond tolerance. \"\n",
    "              f\"Epochs without improvement: {epochs_without_improvement}/{patience}.\")\n",
    "        \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1} due to no improvement after {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "\n",
    "NAME =f\"Pixel_32x32x4to32x32x4_dilRESNET_BnW_30k_SimtoExp_Model_v{currentMonth}{currentDay}_Cluster_GPU_tfData-{int(time.time())}\"  # change this later to incorporate exact date \n",
    "torch.save(model.state_dict(), f'/hpc/group/youlab/ks723/miniconda3/saved_models/trained/{NAME}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Saving losses \n",
    "\"\"\"\n",
    "\n",
    "# Save losses and model details in a JSON file at the end of training\n",
    "losses = {\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'best_loss': best_loss\n",
    "}\n",
    "\n",
    "with open(f'/hpc/group/youlab/ks723/miniconda3/saved_models/logs/losses_{NAME}.json', 'w') as f:\n",
    "    json.dump(losses, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plotting training and validation losses\n",
    "\"\"\"\n",
    "# Function to plot training and test losses with custom style\n",
    "def plot_losses(train_losses, test_losses):\n",
    "    sns.set(style='darkgrid', rc={\"axes.facecolor\": \"black\", \"grid.color\": \"grey\"})  # Setting the style\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    epochs = np.arange(1, len(train_losses) + 1)  # Assuming train_losses and test_losses are of the same length\n",
    "    \n",
    "    plt.plot(epochs, train_losses, label='Training Loss', color='cyan', linewidth=2)  # Thicker line for Training Loss\n",
    "    plt.plot(epochs, test_losses, label='Test Loss', color='magenta', linewidth=2)  # Thicker line for Test Loss\n",
    "    \n",
    "    plt.title('Training and Test Losses', color='black')\n",
    "    plt.xlabel('Epochs', color='black')\n",
    "    plt.ylabel('Loss', color='black')\n",
    "    plt.yscale('log')  # Set y-axis to log scale\n",
    "    \n",
    "    plt.tick_params(axis='x', colors='black')  # Change tick color to white\n",
    "    plt.tick_params(axis='y', colors='black')  # Change tick color to white\n",
    "    \n",
    "    plt.legend(facecolor='black', edgecolor='white', fontsize='medium', fancybox=True, framealpha=1, shadow=True, borderpad=1, labelcolor='white')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Make sure to call this function after the training loop\n",
    "plot_losses(train_losses, test_losses)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_pytorch_ipy_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

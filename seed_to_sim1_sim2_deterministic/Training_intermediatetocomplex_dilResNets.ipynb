{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-19 12:23:26,874] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from diffusers import AutoencoderKL\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/group/youlab/ks723/miniconda3/envs/test_pytorch_ipy/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\")\n",
    "\n",
    "\n",
    "# torch_device = \"cuda\"\n",
    "# vae.to(torch_device)\n",
    "\n",
    "def encode_img(input_img):\n",
    "    input_img = input_img.repeat(3, 1, 1)\n",
    "    \n",
    "    # Single image -> single latent in a batch (so size 1, 4, 64, 64)\n",
    "    if len(input_img.shape)<4:\n",
    "        input_img = input_img.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        latent = vae.encode(input_img*2 - 1) # Note scaling  # to make outputs from -1 to 1 \n",
    "    return 0.18215 * latent.latent_dist.sample()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def decode_img(latents):\n",
    "    # bath of latents -> list of images\n",
    "    latents = (1 / 0.18215) * latents\n",
    "    with torch.no_grad():\n",
    "        image = vae.decode(latents).sample\n",
    "    image = (image / 2 + 0.5).clamp(0, 1)    # to make outputs from 0 to 1 \n",
    "    image = image.detach()\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "foldername='/hpc/group/youlab/ks723/miniconda3/Lingchong/Latents'\n",
    "latentname_input='latent_dim_75000_4channels_4x32x32_newintermediate102.pickle'\n",
    "latentname_output='latent_dim_75000_4channels_4x32x32_newcomplex102.pickle'\n",
    "\n",
    "filename_input=os.path.join(foldername,latentname_input)\n",
    "filename_output=os.path.join(foldername,latentname_output)\n",
    "\n",
    "pickle_in=open(filename_input,\"rb\")\n",
    "# pickle_in=open(\"latent_dim_120000_4channels_4x32x32_Tp2.pickle\",\"rb\")\n",
    "\n",
    "yprime_in=pickle.load(pickle_in)\n",
    "# yprime=yprime.reshape(-1,img_width,img_length,4)\n",
    "\n",
    "yprime_in=yprime_in[:30000,:,:,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pickle_in_output=open(filename_output,\"rb\")\n",
    "yprime_in_output=pickle.load(pickle_in_output)\n",
    "# yprime=yprime.reshape(-1,img_width,img_length,4)\n",
    "\n",
    "yprime_in_output=yprime_in_output[:30000,:,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprime_in=torch.Tensor(yprime_in)\n",
    "yprime_in_output=torch.Tensor(yprime_in_output)\n",
    "\n",
    "yprime_scaled_in=yprime_in\n",
    "yprime_scaled_in_output=yprime_in_output\n",
    "\n",
    "# yprime_scaled=yprime\n",
    "yprime_scaled_in=yprime_scaled_in.float()\n",
    "yprime_scaled_in_output=yprime_scaled_in_output.float()\n",
    "\n",
    "\n",
    "# Define train and test datasets\n",
    "dataset = torch.utils.data.TensorDataset(yprime_scaled_in, yprime_scaled_in_output)\n",
    "# Split dataset into train and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size=64\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(val_dataset,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Total Parameters in Neural Network: 2668100\n",
      "Epoch 1: Significant improvement observed. Best Validation Loss updated to 0.623053.\n",
      "Epoch [2/500] Train Loss: 0.566584 | Test Loss: 0.542455| lr: 0.0001000\n",
      "Epoch 2: Significant improvement observed. Best Validation Loss updated to 0.542455.\n",
      "Epoch 3: Significant improvement observed. Best Validation Loss updated to 0.512418.\n",
      "Epoch [4/500] Train Loss: 0.490865 | Test Loss: 0.468275| lr: 0.0002000\n",
      "Epoch 4: Significant improvement observed. Best Validation Loss updated to 0.468275.\n",
      "Epoch 5: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [6/500] Train Loss: 0.429186 | Test Loss: 0.413956| lr: 0.0003000\n",
      "Epoch 6: Significant improvement observed. Best Validation Loss updated to 0.413956.\n",
      "Epoch 7: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [8/500] Train Loss: 0.388828 | Test Loss: 0.496784| lr: 0.0004000\n",
      "Epoch 8: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 9: Significant improvement observed. Best Validation Loss updated to 0.362266.\n",
      "Epoch [10/500] Train Loss: 0.352687 | Test Loss: 0.345706| lr: 0.0005000\n",
      "Epoch 10: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 11: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch [12/500] Train Loss: 0.324776 | Test Loss: 0.335503| lr: 0.0004901\n",
      "Epoch 12: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 13: Significant improvement observed. Best Validation Loss updated to 0.321312.\n",
      "Epoch [14/500] Train Loss: 0.297141 | Test Loss: 1.736275| lr: 0.0004803\n",
      "Epoch 14: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 15: Validation loss increased beyond tolerance. Epochs without improvement: 2/20.\n",
      "Epoch [16/500] Train Loss: 0.278617 | Test Loss: 0.973917| lr: 0.0004707\n",
      "Epoch 16: Validation loss increased beyond tolerance. Epochs without improvement: 3/20.\n",
      "Epoch 17: Validation loss increased beyond tolerance. Epochs without improvement: 4/20.\n",
      "Epoch [18/500] Train Loss: 0.262818 | Test Loss: 0.311284| lr: 0.0004614\n",
      "Epoch 18: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 19: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch [20/500] Train Loss: 0.250310 | Test Loss: 0.447696| lr: 0.0004522\n",
      "Epoch 20: Validation loss increased beyond tolerance. Epochs without improvement: 2/20.\n",
      "Epoch 21: Validation loss increased beyond tolerance. Epochs without improvement: 3/20.\n",
      "Epoch 22: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 23: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 24: Validation loss increased beyond tolerance. Epochs without improvement: 2/20.\n",
      "Epoch 25: Validation loss increased beyond tolerance. Epochs without improvement: 3/20.\n",
      "Epoch 26: Validation loss increased beyond tolerance. Epochs without improvement: 4/20.\n",
      "Epoch 27: Validation loss increased beyond tolerance. Epochs without improvement: 5/20.\n",
      "Epoch 28: Validation loss increased beyond tolerance. Epochs without improvement: 6/20.\n",
      "Epoch 29: Validation loss increased beyond tolerance. Epochs without improvement: 7/20.\n",
      "Epoch 30: Validation loss increased beyond tolerance. Epochs without improvement: 8/20.\n",
      "Epoch 31: Validation loss increased beyond tolerance. Epochs without improvement: 9/20.\n",
      "Epoch 32: Validation loss increased beyond tolerance. Epochs without improvement: 10/20.\n",
      "Epoch 33: Validation loss increased beyond tolerance. Epochs without improvement: 11/20.\n",
      "Epoch 34: Validation loss increased beyond tolerance. Epochs without improvement: 12/20.\n",
      "Epoch 35: Significant improvement observed. Best Validation Loss updated to 0.239192.\n",
      "Epoch 36: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 37: Validation loss increased beyond tolerance. Epochs without improvement: 2/20.\n",
      "Epoch 38: Validation loss increased beyond tolerance. Epochs without improvement: 3/20.\n",
      "Epoch 39: Validation loss increased beyond tolerance. Epochs without improvement: 4/20.\n",
      "Epoch [40/500] Train Loss: 0.178278 | Test Loss: 2.134336| lr: 0.0003699\n",
      "Epoch 40: Validation loss increased beyond tolerance. Epochs without improvement: 5/20.\n",
      "Epoch 41: Validation loss increased beyond tolerance. Epochs without improvement: 6/20.\n",
      "Epoch 42: Validation loss increased beyond tolerance. Epochs without improvement: 7/20.\n",
      "Epoch 43: Validation loss increased beyond tolerance. Epochs without improvement: 8/20.\n",
      "Epoch 44: Validation loss increased beyond tolerance. Epochs without improvement: 9/20.\n",
      "Epoch 45: Validation loss increased beyond tolerance. Epochs without improvement: 10/20.\n",
      "Epoch 46: Validation loss increased beyond tolerance. Epochs without improvement: 11/20.\n",
      "Epoch 47: Validation loss increased beyond tolerance. Epochs without improvement: 12/20.\n",
      "Epoch 48: Validation loss increased beyond tolerance. Epochs without improvement: 13/20.\n",
      "Epoch 49: Validation loss increased beyond tolerance. Epochs without improvement: 14/20.\n",
      "Epoch 50: Validation loss increased beyond tolerance. Epochs without improvement: 15/20.\n",
      "Epoch 51: Validation loss increased beyond tolerance. Epochs without improvement: 16/20.\n",
      "Epoch 52: Validation loss increased beyond tolerance. Epochs without improvement: 17/20.\n",
      "Epoch 53: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 54: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 55: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 56: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 57: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 58: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 59: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 60: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 61: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 62: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 63: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 64: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 65: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 66: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 67: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 68: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 69: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 70: Validation loss increased beyond tolerance. Epochs without improvement: 2/20.\n",
      "Epoch 71: Validation loss increased beyond tolerance. Epochs without improvement: 3/20.\n",
      "Epoch 72: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 73: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 74: Validation loss increased beyond tolerance. Epochs without improvement: 2/20.\n",
      "Epoch 75: Validation loss increased beyond tolerance. Epochs without improvement: 3/20.\n",
      "Epoch 76: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 77: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 78: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 79: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [80/500] Train Loss: 0.128804 | Test Loss: 0.311845| lr: 0.0002474\n",
      "Epoch 80: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 81: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 82: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 83: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 84: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 85: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 86: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 87: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 88: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 89: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 90: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 91: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 92: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 93: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 94: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 95: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 96: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 97: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 98: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 99: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 100: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 101: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 102: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 103: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 104: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 105: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 106: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 107: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 108: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 109: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 110: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 111: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 112: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 113: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 114: Validation loss increased beyond tolerance. Epochs without improvement: 2/20.\n",
      "Epoch 115: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 116: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 117: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 118: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 119: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [120/500] Train Loss: 0.108603 | Test Loss: 0.225782| lr: 0.0001655\n",
      "Epoch 120: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 121: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 122: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 123: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 124: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 125: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 126: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 127: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 128: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 129: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 130: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 131: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 132: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 133: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 134: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 135: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 136: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 137: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 138: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 139: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 140: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 141: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 142: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 143: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 144: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 145: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 146: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 147: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 148: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 149: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 150: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 151: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 152: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 153: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 154: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 155: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 156: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 157: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 158: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 159: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [160/500] Train Loss: 0.097304 | Test Loss: 0.231374| lr: 0.0001107\n",
      "Epoch 160: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 161: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 162: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 163: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 164: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 165: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 166: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 167: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 168: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 169: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 170: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 171: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 172: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 173: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 174: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 175: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 176: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 177: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 178: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 179: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 180: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 181: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 182: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 183: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 184: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 185: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 186: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 187: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 188: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 189: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 190: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 191: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 192: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 193: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 194: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 195: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 196: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 197: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 198: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 199: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [200/500] Train Loss: 0.090418 | Test Loss: 0.243377| lr: 0.0000741\n",
      "Epoch 200: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 201: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 202: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 203: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 204: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 205: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 206: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 207: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 208: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 209: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 210: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 211: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 212: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 213: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 214: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 215: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 216: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 217: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 218: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 219: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 220: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 221: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 222: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 223: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 224: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 225: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 226: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 227: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 228: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 229: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 230: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 231: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 232: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 233: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 234: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 235: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 236: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 237: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 238: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 239: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [240/500] Train Loss: 0.085565 | Test Loss: 0.244701| lr: 0.0000496\n",
      "Epoch 240: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 241: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 242: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 243: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 244: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 245: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 246: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 247: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 248: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 249: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 250: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 251: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 252: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 253: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 254: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 255: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 256: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 257: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 258: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 259: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 260: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 261: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 262: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 263: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 264: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 265: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 266: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 267: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 268: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 269: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 270: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 271: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 272: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 273: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 274: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 275: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 276: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 277: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 278: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 279: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [280/500] Train Loss: 0.082452 | Test Loss: 0.243335| lr: 0.0000331\n",
      "Epoch 280: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 281: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 282: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 283: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 284: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 285: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 286: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 287: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 288: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 289: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 290: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 291: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 292: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 293: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 294: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 295: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 296: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 297: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 298: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 299: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 300: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 301: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 302: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 303: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 304: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 305: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 306: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 307: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 308: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 309: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 310: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 311: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 312: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 313: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 314: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 315: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 316: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 317: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 318: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 319: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [320/500] Train Loss: 0.080321 | Test Loss: 0.241823| lr: 0.0000222\n",
      "Epoch 320: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 321: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 322: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 323: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 324: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 325: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 326: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 327: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 328: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 329: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 330: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 331: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 332: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 333: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 334: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 335: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 336: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 337: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 338: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 339: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 340: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 341: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 342: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 343: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 344: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 345: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 346: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 347: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 348: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 349: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 350: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 351: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 352: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 353: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 354: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 355: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 356: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 357: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 358: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 359: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [360/500] Train Loss: 0.079123 | Test Loss: 0.248249| lr: 0.0000148\n",
      "Epoch 360: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 361: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 362: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 363: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 364: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 365: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 366: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 367: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 368: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 369: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 370: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 371: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 372: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 373: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 374: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 375: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 376: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 377: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 378: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 379: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 380: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 381: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 382: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 383: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 384: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 385: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 386: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 387: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 388: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 389: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 390: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 391: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 392: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 393: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 394: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 395: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 396: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 397: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 398: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 399: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [400/500] Train Loss: 0.077989 | Test Loss: 0.245841| lr: 0.0000099\n",
      "Epoch 400: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 401: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 402: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 403: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 404: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 405: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 406: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 407: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 408: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 409: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 410: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 411: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 412: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 413: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 414: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 415: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 416: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 417: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 418: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 419: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 420: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 421: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 422: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 423: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 424: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 425: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 426: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 427: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 428: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 429: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 430: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 431: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 432: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 433: Validation loss increased beyond tolerance. Epochs without improvement: 1/20.\n",
      "Epoch 434: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 435: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 436: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 437: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 438: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 439: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [440/500] Train Loss: 0.077244 | Test Loss: 0.255886| lr: 0.0000066\n",
      "Epoch 440: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 441: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 442: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 443: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 444: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 445: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 446: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 447: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 448: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 449: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 450: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 451: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 452: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 453: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 454: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 455: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 456: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 457: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 458: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 459: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 460: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 461: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 462: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 463: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 464: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 465: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 466: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 467: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 468: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 469: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 470: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 471: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 472: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 473: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 474: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 475: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 476: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 477: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 478: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 479: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [480/500] Train Loss: 0.077010 | Test Loss: 0.259284| lr: 0.0000050\n",
      "Epoch 480: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 481: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 482: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 483: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 484: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 485: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 486: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 487: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 488: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 489: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 490: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 491: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 492: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 493: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 494: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 495: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 496: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 497: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 498: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch 499: Validation loss increased but within tolerance (0.03). Continuing training.\n",
      "Epoch [500/500] Train Loss: 0.076755 | Test Loss: 0.257830| lr: 0.0000050\n",
      "Epoch 500: Validation loss increased but within tolerance (0.03). Continuing training.\n"
     ]
    }
   ],
   "source": [
    "# Dilated Basic Block similar to PDEArena\n",
    "class PDEArenaDilatedBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, dilation_rates, activation=nn.ReLU, norm=True):\n",
    "        super(PDEArenaDilatedBlock, self).__init__()\n",
    "\n",
    "        # Create dilated convolution layers with specified dilation rates\n",
    "        self.dilated_layers = nn.ModuleList([\n",
    "            nn.Conv2d(\n",
    "                in_planes if i == 0 else out_planes, \n",
    "                out_planes, \n",
    "                kernel_size=3, \n",
    "                padding=rate, \n",
    "                dilation=rate, \n",
    "                bias=False\n",
    "            )\n",
    "            for i, rate in enumerate(dilation_rates)\n",
    "        ])\n",
    "        \n",
    "        # Normalization and Activation layers\n",
    "        self.norm_layers = nn.ModuleList([nn.BatchNorm2d(out_planes) if norm else nn.Identity() for _ in dilation_rates])\n",
    "        self.activation = activation(inplace=True)\n",
    "\n",
    "        # Shortcut (1x1 convolution if input and output planes differ)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_planes) if norm else nn.Identity()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for layer, norm in zip(self.dilated_layers, self.norm_layers):\n",
    "            out = self.activation(norm(layer(out)))\n",
    "        return out + self.shortcut(x)  # Residual connection\n",
    "\n",
    "# Dilated ResNet with Adjustable Layers and Blocks\n",
    "class PDEArenaDilatedResNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels=64, num_blocks=15, dilation_rates=[1, 2, 4, 8], activation=nn.ReLU, norm=True):\n",
    "        super(PDEArenaDilatedResNet, self).__init__()\n",
    "        \n",
    "        self.in_conv = nn.Conv2d(in_channels, hidden_channels, kernel_size=3, padding=1)  # Input layer\n",
    "        \n",
    "        # Stack of dilated blocks\n",
    "        self.layers = nn.Sequential(\n",
    "            *[PDEArenaDilatedBlock(hidden_channels, hidden_channels, dilation_rates, activation=activation, norm=norm) for _ in range(num_blocks)]\n",
    "        )\n",
    "        \n",
    "        self.out_conv = nn.Conv2d(hidden_channels, out_channels, kernel_size=3, padding=1)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_conv(x)\n",
    "        x = self.layers(x)\n",
    "        return self.out_conv(x)\n",
    "\n",
    "# Example usage\n",
    "model = PDEArenaDilatedResNet(\n",
    "    in_channels=4,               # Input channels (e.g., RGB image)\n",
    "    out_channels=4,              # Output channels (e.g., RGB image or latent channels)\n",
    "    hidden_channels=64,          # Number of hidden channels\n",
    "    num_blocks=18,               # Number of dilated blocks (similar to number of ResNet blocks)\n",
    "    dilation_rates=[1, 2, 4, 8], # Dilation rates for multi-scale feature capture\n",
    "    activation=nn.ReLU,          # Activation function\n",
    "    norm=True                    # Use BatchNorm after each convolution\n",
    ")\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "currentSecond= datetime.now().second\n",
    "currentMinute = datetime.now().minute\n",
    "currentHour = datetime.now().hour\n",
    "\n",
    "currentDay = datetime.now().day\n",
    "currentMonth = datetime.now().month\n",
    "currentYear = datetime.now().year\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 500      \n",
    "warmup_epochs=10\n",
    "lr = 5e-4               #for fine tuning.\n",
    "min_lr = 5e-6\n",
    "gamma = 0.99\n",
    "\n",
    "# Training parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# model = ICToLatent()\n",
    "#model.load_state_dict(torch.load('trained/pred_patterns_resnet.V1.pt'))\n",
    "model.to(device)\n",
    "print(f\"Total Parameters in Neural Network: {count_parameters(model)}\")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "train_losses=[]\n",
    "test_losses=[]\n",
    "\n",
    "# Training parameters and early stopping initialization\n",
    "best_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "patience = 20\n",
    "delta = 0.03\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_params, batch_latents in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch_params.to(device))\n",
    "        loss = criterion(outputs, batch_latents.squeeze(1).to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Warm-up schedule\n",
    "        if epoch < warmup_epochs:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * (epoch + 1) / warmup_epochs\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "\n",
    "    # Scheduler step after warmup\n",
    "    if epoch >= warmup_epochs:\n",
    "        scheduler.step()\n",
    "    param_group['lr'] = max(param_group['lr'], min_lr)\n",
    "\n",
    "   \n",
    "\n",
    "    # Validation loop for testing set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_params, batch_latents in test_loader:\n",
    "            outputs = model(batch_params.to(device))\n",
    "            loss = criterion(outputs, batch_latents.squeeze(1).to(device))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    # Store losses in lists\n",
    "    train_losses.append(avg_train_loss)\n",
    "    test_losses.append(avg_val_loss)\n",
    "\n",
    "    interval = 2 if epoch < 20 else 40\n",
    "    if (epoch + 1)%interval == 0 or epoch+1 == num_epochs:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] Train Loss: {running_loss / len(train_loader):.6f} | Test Loss: {val_loss / len(test_loader):.6f}| lr: {param_group['lr']:0.7f}\")\n",
    "    \n",
    "    \n",
    "    # Early stopping logic with tolerance\n",
    "    if avg_val_loss < best_loss - delta:\n",
    "        # Significant improvement\n",
    "        best_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        print(f\"Epoch {epoch + 1}: Significant improvement observed. Best Validation Loss updated to {best_loss:.6f}.\")\n",
    "    elif avg_val_loss <= best_loss + delta:\n",
    "        # Within tolerance\n",
    "        epochs_without_improvement = 0\n",
    "        print(f\"Epoch {epoch + 1}: Validation loss increased but within tolerance ({delta}). Continuing training.\")\n",
    "    else:\n",
    "        # Exceeded tolerance\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Epoch {epoch + 1}: Validation loss increased beyond tolerance. Epochs without improvement: {epochs_without_improvement}/{patience}.\")\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1} due to no improvement after {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "\n",
    "NAME =f\"Pixel_32x32x3to32x32x4_dilRESNET_newpatterns_intermediatetocomplex_Model_v{currentMonth}{currentDay}_Cluster_GPU_tfData-{int(time.time())}\"  # change this later to incorporate exact date \n",
    "torch.save(model.state_dict(), f'/hpc/group/youlab/ks723/miniconda3/saved_models/trained/{NAME}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Total Parameters in Neural Network: 1247876\n",
      "Epoch 1: Significant improvement observed. Best Validation Loss updated to 0.533948.\n",
      "Epoch [2/1000] Train Loss: 0.477453 | Test Loss: 0.438263| lr: 0.0001000\n",
      "Epoch 2: Significant improvement observed. Best Validation Loss updated to 0.438263.\n",
      "Epoch 3: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [4/1000] Train Loss: 0.368465 | Test Loss: 0.354170| lr: 0.0002000\n",
      "Epoch 4: Significant improvement observed. Best Validation Loss updated to 0.354170.\n",
      "Epoch 5: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [6/1000] Train Loss: 0.318760 | Test Loss: 0.311396| lr: 0.0003000\n",
      "Epoch 6: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 7: Significant improvement observed. Best Validation Loss updated to 0.299000.\n",
      "Epoch [8/1000] Train Loss: 0.288561 | Test Loss: 0.287815| lr: 0.0004000\n",
      "Epoch 8: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 9: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [10/1000] Train Loss: 0.266889 | Test Loss: 0.272492| lr: 0.0005000\n",
      "Epoch 10: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 11: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [12/1000] Train Loss: 0.246566 | Test Loss: 0.251937| lr: 0.0004901\n",
      "Epoch 12: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 13: Significant improvement observed. Best Validation Loss updated to 0.242644.\n",
      "Epoch [14/1000] Train Loss: 0.232203 | Test Loss: 0.248415| lr: 0.0004803\n",
      "Epoch 14: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 15: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [16/1000] Train Loss: 0.219395 | Test Loss: 0.232400| lr: 0.0004707\n",
      "Epoch 16: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 17: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [18/1000] Train Loss: 0.210154 | Test Loss: 0.223226| lr: 0.0004614\n",
      "Epoch 18: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 19: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [20/1000] Train Loss: 0.202791 | Test Loss: 0.216289| lr: 0.0004522\n",
      "Epoch 20: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 21: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 22: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 23: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 24: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 25: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 26: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 27: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 28: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 29: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 30: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 31: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 32: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 33: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 34: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 35: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 36: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 37: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 38: Significant improvement observed. Best Validation Loss updated to 0.191637.\n",
      "Epoch 39: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [40/1000] Train Loss: 0.161044 | Test Loss: 0.206295| lr: 0.0003699\n",
      "Epoch 40: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 41: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 42: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 43: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 44: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 45: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 46: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 47: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 48: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 49: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 50: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 51: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 52: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 53: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 54: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 55: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 56: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 57: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 58: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 59: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 60: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 61: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 62: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 63: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 64: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 65: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 66: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 67: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 68: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 69: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 70: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 71: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 72: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 73: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 74: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 75: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 76: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 77: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 78: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 79: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [80/1000] Train Loss: 0.130128 | Test Loss: 0.196072| lr: 0.0002474\n",
      "Epoch 80: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 81: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 82: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 83: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 84: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 85: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 86: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 87: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 88: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 89: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 90: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 91: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 92: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 93: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 94: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 95: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 96: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 97: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 98: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 99: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 100: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 101: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 102: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 103: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 104: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 105: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 106: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 107: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 108: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 109: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 110: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 111: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 112: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 113: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 114: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 115: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 116: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 117: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 118: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 119: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [120/1000] Train Loss: 0.114764 | Test Loss: 0.194753| lr: 0.0001655\n",
      "Epoch 120: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 121: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 122: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 123: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 124: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 125: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 126: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 127: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 128: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 129: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 130: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 131: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 132: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 133: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 134: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 135: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 136: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 137: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 138: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 139: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 140: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 141: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 142: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 143: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 144: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 145: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 146: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 147: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 148: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 149: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 150: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 151: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 152: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 153: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 154: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 155: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 156: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 157: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 158: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 159: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [160/1000] Train Loss: 0.105594 | Test Loss: 0.193984| lr: 0.0001107\n",
      "Epoch 160: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 161: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 162: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 163: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 164: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 165: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 166: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 167: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 168: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 169: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 170: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 171: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 172: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 173: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 174: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 175: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 176: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 177: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 178: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 179: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 180: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 181: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 182: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 183: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 184: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 185: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 186: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 187: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 188: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 189: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 190: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 191: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 192: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 193: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 194: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 195: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 196: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 197: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 198: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 199: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [200/1000] Train Loss: 0.099907 | Test Loss: 0.198017| lr: 0.0000741\n",
      "Epoch 200: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 201: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 202: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 203: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 204: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 205: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 206: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 207: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 208: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 209: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 210: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 211: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 212: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 213: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 214: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 215: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 216: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 217: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 218: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 219: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 220: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 221: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 222: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 223: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 224: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 225: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 226: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 227: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 228: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 229: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 230: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 231: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 232: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 233: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 234: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 235: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 236: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 237: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 238: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 239: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [240/1000] Train Loss: 0.096420 | Test Loss: 0.201144| lr: 0.0000496\n",
      "Epoch 240: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 241: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 242: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 243: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 244: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 245: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 246: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 247: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 248: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 249: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 250: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 251: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 252: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 253: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 254: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 255: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 256: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 257: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 258: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 259: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 260: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 261: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 262: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 263: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 264: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 265: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 266: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 267: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 268: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 269: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 270: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 271: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 272: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 273: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 274: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 275: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 276: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 277: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 278: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 279: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [280/1000] Train Loss: 0.093392 | Test Loss: 0.202032| lr: 0.0000331\n",
      "Epoch 280: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 281: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 282: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 283: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 284: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 285: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 286: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 287: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 288: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 289: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 290: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 291: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 292: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 293: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 294: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 295: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 296: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 297: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 298: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 299: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 300: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 301: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 302: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 303: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 304: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 305: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 306: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 307: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 308: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 309: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 310: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 311: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 312: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 313: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 314: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 315: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 316: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 317: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 318: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 319: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [320/1000] Train Loss: 0.092020 | Test Loss: 0.203682| lr: 0.0000222\n",
      "Epoch 320: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 321: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 322: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 323: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 324: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 325: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 326: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 327: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 328: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 329: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 330: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 331: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 332: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 333: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 334: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 335: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 336: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 337: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 338: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 339: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 340: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 341: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 342: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 343: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 344: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 345: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 346: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 347: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 348: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 349: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 350: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 351: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 352: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 353: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 354: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 355: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 356: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 357: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 358: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 359: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [360/1000] Train Loss: 0.090897 | Test Loss: 0.204482| lr: 0.0000148\n",
      "Epoch 360: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 361: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 362: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 363: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 364: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 365: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 366: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 367: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 368: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 369: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 370: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 371: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 372: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 373: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 374: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 375: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 376: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 377: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 378: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 379: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 380: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 381: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 382: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 383: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 384: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 385: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 386: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 387: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 388: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 389: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 390: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 391: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 392: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 393: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 394: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 395: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 396: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 397: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 398: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 399: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [400/1000] Train Loss: 0.090067 | Test Loss: 0.205273| lr: 0.0000099\n",
      "Epoch 400: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 401: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 402: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 403: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 404: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 405: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 406: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 407: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 408: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 409: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 410: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 411: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 412: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 413: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 414: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 415: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 416: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 417: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 418: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 419: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 420: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 421: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 422: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 423: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 424: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 425: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 426: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 427: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 428: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 429: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 430: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 431: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 432: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 433: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 434: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 435: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 436: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 437: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 438: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 439: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [440/1000] Train Loss: 0.089627 | Test Loss: 0.205956| lr: 0.0000066\n",
      "Epoch 440: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 441: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 442: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 443: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 444: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 445: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 446: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 447: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 448: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 449: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 450: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 451: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 452: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 453: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 454: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 455: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 456: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 457: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 458: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 459: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 460: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 461: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 462: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 463: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 464: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 465: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 466: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 467: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 468: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 469: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 470: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 471: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 472: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 473: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 474: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 475: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 476: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 477: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 478: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 479: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [480/1000] Train Loss: 0.089136 | Test Loss: 0.206102| lr: 0.0000050\n",
      "Epoch 480: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 481: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 482: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 483: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 484: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 485: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 486: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 487: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 488: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 489: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 490: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 491: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 492: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 493: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 494: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 495: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 496: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 497: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 498: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 499: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 500: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 501: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 502: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 503: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 504: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 505: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 506: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 507: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 508: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 509: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 510: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 511: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 512: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 513: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 514: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 515: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 516: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 517: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 518: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 519: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [520/1000] Train Loss: 0.089037 | Test Loss: 0.206629| lr: 0.0000050\n",
      "Epoch 520: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 521: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 522: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 523: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 524: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 525: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 526: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 527: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 528: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 529: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 530: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 531: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 532: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 533: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 534: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 535: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 536: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 537: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 538: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 539: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 540: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 541: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 542: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 543: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 544: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 545: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 546: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 547: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 548: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 549: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 550: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 551: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 552: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 553: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 554: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 555: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 556: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 557: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 558: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 559: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [560/1000] Train Loss: 0.089020 | Test Loss: 0.206599| lr: 0.0000050\n",
      "Epoch 560: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 561: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 562: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 563: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 564: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 565: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 566: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 567: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 568: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 569: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 570: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 571: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 572: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 573: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 574: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 575: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 576: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 577: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 578: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 579: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 580: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 581: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 582: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 583: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 584: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 585: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 586: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 587: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 588: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 589: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 590: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 591: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 592: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 593: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 594: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 595: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 596: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 597: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 598: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 599: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [600/1000] Train Loss: 0.088917 | Test Loss: 0.206826| lr: 0.0000050\n",
      "Epoch 600: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 601: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 602: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 603: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 604: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 605: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 606: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 607: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 608: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 609: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 610: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 611: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 612: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 613: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 614: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 615: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 616: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 617: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 618: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 619: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 620: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 621: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 622: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 623: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 624: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 625: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 626: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 627: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 628: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 629: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 630: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 631: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 632: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 633: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 634: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 635: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 636: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 637: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 638: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 639: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [640/1000] Train Loss: 0.088829 | Test Loss: 0.207168| lr: 0.0000050\n",
      "Epoch 640: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 641: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 642: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 643: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 644: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 645: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 646: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 647: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 648: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 649: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 650: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 651: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 652: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 653: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 654: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 655: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 656: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 657: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 658: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 659: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 660: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 661: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 662: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 663: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 664: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 665: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 666: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 667: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 668: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 669: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 670: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 671: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 672: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 673: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 674: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 675: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 676: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 677: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 678: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 679: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [680/1000] Train Loss: 0.088815 | Test Loss: 0.207108| lr: 0.0000050\n",
      "Epoch 680: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 681: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 682: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 683: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 684: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 685: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 686: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 687: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 688: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 689: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 690: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 691: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 692: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 693: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 694: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 695: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 696: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 697: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 698: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 699: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 700: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 701: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 702: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 703: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 704: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 705: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 706: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 707: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 708: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 709: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 710: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 711: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 712: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 713: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 714: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 715: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 716: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 717: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 718: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 719: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [720/1000] Train Loss: 0.088591 | Test Loss: 0.207532| lr: 0.0000050\n",
      "Epoch 720: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 721: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 722: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 723: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 724: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 725: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 726: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 727: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 728: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 729: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 730: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 731: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 732: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 733: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 734: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 735: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 736: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 737: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 738: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 739: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 740: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 741: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 742: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 743: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 744: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 745: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 746: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 747: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 748: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 749: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 750: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 751: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 752: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 753: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 754: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 755: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 756: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 757: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 758: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 759: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [760/1000] Train Loss: 0.088601 | Test Loss: 0.207824| lr: 0.0000050\n",
      "Epoch 760: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 761: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 762: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 763: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 764: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 765: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 766: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 767: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 768: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 769: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 770: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 771: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 772: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 773: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 774: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 775: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 776: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 777: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 778: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 779: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 780: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 781: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 782: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 783: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 784: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 785: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 786: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 787: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 788: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 789: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 790: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 791: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 792: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 793: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 794: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 795: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 796: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 797: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 798: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 799: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [800/1000] Train Loss: 0.088307 | Test Loss: 0.207947| lr: 0.0000050\n",
      "Epoch 800: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 801: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 802: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 803: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 804: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 805: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 806: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 807: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 808: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 809: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 810: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 811: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 812: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 813: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 814: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 815: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 816: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 817: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 818: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 819: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 820: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 821: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 822: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 823: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 824: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 825: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 826: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 827: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 828: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 829: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 830: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 831: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 832: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 833: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 834: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 835: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 836: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 837: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 838: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 839: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [840/1000] Train Loss: 0.088401 | Test Loss: 0.207954| lr: 0.0000050\n",
      "Epoch 840: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 841: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 842: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 843: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 844: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 845: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 846: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 847: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 848: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 849: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 850: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 851: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 852: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 853: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 854: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 855: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 856: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 857: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 858: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 859: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 860: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 861: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 862: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 863: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 864: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 865: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 866: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 867: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 868: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 869: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 870: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 871: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 872: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 873: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 874: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 875: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 876: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 877: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 878: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 879: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [880/1000] Train Loss: 0.088411 | Test Loss: 0.208322| lr: 0.0000050\n",
      "Epoch 880: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 881: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 882: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 883: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 884: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 885: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 886: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 887: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 888: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 889: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 890: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 891: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 892: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 893: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 894: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 895: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 896: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 897: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 898: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 899: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 900: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 901: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 902: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 903: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 904: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 905: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 906: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 907: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 908: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 909: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 910: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 911: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 912: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 913: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 914: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 915: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 916: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 917: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 918: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 919: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [920/1000] Train Loss: 0.088177 | Test Loss: 0.208534| lr: 0.0000050\n",
      "Epoch 920: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 921: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 922: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 923: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 924: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 925: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 926: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 927: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 928: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 929: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 930: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 931: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 932: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 933: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 934: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 935: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 936: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 937: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 938: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 939: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 940: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 941: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 942: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 943: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 944: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 945: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 946: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 947: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 948: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 949: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 950: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 951: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 952: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 953: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 954: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 955: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 956: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 957: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 958: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 959: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [960/1000] Train Loss: 0.087861 | Test Loss: 0.208716| lr: 0.0000050\n",
      "Epoch 960: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 961: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 962: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 963: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 964: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 965: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 966: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 967: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 968: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 969: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 970: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 971: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 972: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 973: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 974: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 975: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 976: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 977: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 978: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 979: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 980: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 981: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 982: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 983: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 984: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 985: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 986: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 987: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 988: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 989: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 990: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 991: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 992: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 993: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 994: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 995: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 996: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 997: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 998: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch 999: Validation loss increased but within tolerance (0.05). Continuing training.\n",
      "Epoch [1000/1000] Train Loss: 0.088227 | Test Loss: 0.208523| lr: 0.0000050\n",
      "Epoch 1000: Validation loss increased but within tolerance (0.05). Continuing training.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000       \n",
    "warmup_epochs=10\n",
    "lr = 5e-4               #for fine tuning.\n",
    "min_lr = 5e-6\n",
    "gamma = 0.99\n",
    "\n",
    "# Training parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = ICToLatent()\n",
    "#model.load_state_dict(torch.load('trained/pred_patterns_resnet.V1.pt'))\n",
    "model.to(device)\n",
    "print(f\"Total Parameters in Neural Network: {count_parameters(model)}\")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "# Training parameters and early stopping initialization # to save best epoch\n",
    "best_loss = float('inf')\n",
    "best_epoch = 0\n",
    "epochs_without_improvement = 0\n",
    "patience = 30\n",
    "delta = 0.05 \n",
    "\n",
    "\n",
    "\n",
    "train_losses=[]\n",
    "test_losses=[]\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_params, batch_latents in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch_params.to(device))\n",
    "        loss = criterion(outputs, batch_latents.squeeze(1).to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Warm-up schedule\n",
    "        if epoch < warmup_epochs:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * (epoch + 1) / warmup_epochs\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "\n",
    "    # Scheduler step after warmup\n",
    "    if epoch >= warmup_epochs:\n",
    "        scheduler.step()\n",
    "    param_group['lr'] = max(param_group['lr'], min_lr)\n",
    "\n",
    "   \n",
    "\n",
    "    # Validation loop for testing set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_params, batch_latents in test_loader:\n",
    "            outputs = model(batch_params.to(device))\n",
    "            loss = criterion(outputs, batch_latents.squeeze(1).to(device))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    # Store losses in lists\n",
    "    train_losses.append(avg_train_loss)\n",
    "    test_losses.append(avg_val_loss)\n",
    "\n",
    "    interval = 2 if epoch < 20 else 40\n",
    "    if (epoch + 1)%interval == 0 or epoch+1 == num_epochs:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] Train Loss: {running_loss / len(train_loader):.6f} | Test Loss: {val_loss / len(test_loader):.6f}| lr: {param_group['lr']:0.7f}\")\n",
    "    \n",
    "    \n",
    "    # Early stopping logic with tolerance\n",
    "    if avg_val_loss < best_loss - delta:\n",
    "        # Significant improvement\n",
    "        best_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        print(f\"Epoch {epoch + 1}: Significant improvement observed. Best Validation Loss updated to {best_loss:.6f}.\")\n",
    "    elif avg_val_loss <= best_loss + delta:\n",
    "        # Within tolerance\n",
    "        epochs_without_improvement = 0\n",
    "        print(f\"Epoch {epoch + 1}: Validation loss increased but within tolerance ({delta}). Continuing training.\")\n",
    "    else:\n",
    "        # Exceeded tolerance\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Epoch {epoch + 1}: Validation loss increased beyond tolerance. Epochs without improvement: {epochs_without_improvement}/{patience}.\")\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1} due to no improvement after {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "\n",
    "NAME =f\"Pixel_32x32x3to32x32x4_RESNET_newpatterns_intermediatetocomplex_Model_v{currentMonth}{currentDay}_Cluster_GPU_tfData-{int(time.time())}\"  # change this later to incorporate exact date \n",
    "torch.save(model.state_dict(), f'/hpc/group/youlab/ks723/miniconda3/saved_models/trained/{NAME}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "\n",
    "import json\n",
    "# Save losses and model details in a JSON file at the end of training\n",
    "losses = {\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'best_loss': best_loss\n",
    "    # 'saved_model_epoch': saved_model_epoch,\n",
    "    # 'model_name': NAME\n",
    "}\n",
    "\n",
    "with open(f'/hpc/group/youlab/ks723/miniconda3/saved_models/logs/losses_{NAME}.json', 'w') as f:\n",
    "    json.dump(losses, f, indent=4)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Function to plot training and test losses with custom style\n",
    "def plot_losses(train_losses, test_losses):\n",
    "    sns.set(style='darkgrid', rc={\"axes.facecolor\": \"black\", \"grid.color\": \"grey\"})  # Setting the style\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    epochs = np.arange(1, len(train_losses) + 1)  # Assuming train_losses and test_losses are of the same length\n",
    "    \n",
    "    plt.plot(epochs, train_losses, label='Training Loss', color='cyan', linewidth=2)  # Thicker line for Training Loss\n",
    "    plt.plot(epochs, test_losses, label='Test Loss', color='magenta', linewidth=2)  # Thicker line for Test Loss\n",
    "    \n",
    "    plt.title('Training and Test Losses', color='black')\n",
    "    plt.xlabel('Epochs', color='black')\n",
    "    plt.ylabel('Loss', color='black')\n",
    "    plt.yscale('log')  # Set y-axis to log scale\n",
    "    \n",
    "    plt.tick_params(axis='x', colors='black')  # Change tick color to white\n",
    "    plt.tick_params(axis='y', colors='black')  # Change tick color to white\n",
    "    \n",
    "    plt.legend(facecolor='black', edgecolor='white', fontsize='medium', fancybox=True, framealpha=1, shadow=True, borderpad=1, labelcolor='white')\n",
    "    plt.show()\n",
    "\n",
    "# Make sure to call this function after the training loop\n",
    "plot_losses(train_losses, test_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_pytorch_ipy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
